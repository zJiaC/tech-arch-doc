import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as s,o as d,c as r,b as e,e as l,a,d as n}from"./app-CUJPFFrd.js";const o="/tech-arch-doc/images/javase-6.png",c="/tech-arch-doc/images/javase-7.png",p="/tech-arch-doc/images/javase-12.png",h="/tech-arch-doc/images/javathread-20240407172652.png",u="/tech-arch-doc/images/javathread-7.png",g="/tech-arch-doc/images/javathread-38.png",_="/tech-arch-doc/images/javathread-47.png",m="/tech-arch-doc/images/javathread-48.png",b="/tech-arch-doc/images/jvm-42.png",v="/tech-arch-doc/images/jvm-43.png",k="/tech-arch-doc/images/jvm-16.png",E="/tech-arch-doc/images/jvm-19.png",f="/tech-arch-doc/images/jvm-27.png",x="/tech-arch-doc/images/jvm-26.png",y="/tech-arch-doc/images/loadclass.png",A="/tech-arch-doc/images/mysql%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B.png",B="/tech-arch-doc/images/%E8%A1%A8%E7%A9%BA%E9%97%B4%E7%BB%93%E6%9E%84.drawio.png",L="/tech-arch-doc/images/bbf9776a54487c1fb9fe2c9f4e1f4bad.png",w="/tech-arch-doc/images/rabbitmq-message-lose-solution.png",S="/tech-arch-doc/images/12347236-28468f4115c0a010.png",C={},R=n('<h1 id="个人经验总结" tabindex="-1"><a class="header-anchor" href="#个人经验总结"><span>个人经验总结</span></a></h1><h2 id="_1-java基础" tabindex="-1"><a class="header-anchor" href="#_1-java基础"><span>1. Java基础</span></a></h2><h3 id="_1-1-数据类型" tabindex="-1"><a class="header-anchor" href="#_1-1-数据类型"><span>1.1 数据类型</span></a></h3><p><img src="'+o+'" alt=""></p><table><thead><tr><th>基本类型</th><th>位数</th><th>字节</th><th>默认值</th></tr></thead><tbody><tr><td><code>int</code></td><td>32</td><td>4</td><td>0</td></tr><tr><td><code>short</code></td><td>16</td><td>2</td><td>0</td></tr><tr><td><code>long</code></td><td>64</td><td>8</td><td>0L</td></tr><tr><td><code>byte</code></td><td>8</td><td>1</td><td>0</td></tr><tr><td><code>char</code></td><td>16</td><td>2</td><td>&#39;u0000&#39;</td></tr><tr><td><code>float</code></td><td>32</td><td>4</td><td>0f</td></tr><tr><td><code>double</code></td><td>64</td><td>8</td><td>0d</td></tr><tr><td><code>boolean</code></td><td>1</td><td></td><td>false</td></tr></tbody></table><h3 id="_1-2-强转" tabindex="-1"><a class="header-anchor" href="#_1-2-强转"><span>1.2 强转</span></a></h3><p><img src="'+c+'" alt=""></p><h3 id="_1-3-访问修饰符" tabindex="-1"><a class="header-anchor" href="#_1-3-访问修饰符"><span>1.3 访问修饰符</span></a></h3><p><img src="'+p+'" alt=""></p><h3 id="_1-4-final-关键字" tabindex="-1"><a class="header-anchor" href="#_1-4-final-关键字"><span>1.4 final 关键字</span></a></h3><ul><li>被 final 修饰的类不可以被继承 <ul><li>String 类被 final 关键字修饰</li></ul></li><li>被 final 修饰的方法不可以被重写</li><li>被 final 修饰的变量不可变，被 final 修饰的变量必须被显式第指定初始值，还得注意的是，这里的不可变指的是变量的引用不可变，不是引用指向的内容的不可变。</li></ul><h3 id="_1-5-integer小知识" tabindex="-1"><a class="header-anchor" href="#_1-5-integer小知识"><span>1.5 Integer小知识:</span></a></h3>',12),M={href:"https://mp.weixin.qq.com/s/mBs5k2LnoGMerpE2vAQzyg",target:"_blank",rel:"noopener noreferrer"},T=e("mark",null,"1000为false而100",-1),N=n(`<div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>Integer a = 1000, b = 1000;  
System.out.println(a == b);
Integer c = 100, d = 100;  
System.out.println(c == d);
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>false
true
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div>`,2),O=n('<h3 id="_1-6-nio-和-io-区别" tabindex="-1"><a class="header-anchor" href="#_1-6-nio-和-io-区别"><span>1.6 NIO 和 IO 区别</span></a></h3><ul><li>NIO 是非阻塞的</li><li>NIO 面向块，I/O 面向流</li></ul><h3 id="_1-7-hashcode-与-equals" tabindex="-1"><a class="header-anchor" href="#_1-7-hashcode-与-equals"><span>1.7 hashCode 与 equals?</span></a></h3><ul><li>如果两个对象相等，则 hashcode ⼀定也是相同的。两个对象相等，对两个对象分别调⽤ equals ⽅法都返回 true。反之，两个对象有相同的 hashcode 值，它们也不⼀定是相等的 。因此，<strong>equals</strong> ⽅法被覆盖过，则 <strong>hashCode</strong> ⽅法也必须被覆盖。</li></ul><h2 id="_2-java-集合" tabindex="-1"><a class="header-anchor" href="#_2-java-集合"><span>2. Java 集合</span></a></h2><h3 id="_2-1-常见集合" tabindex="-1"><a class="header-anchor" href="#_2-1-常见集合"><span>2.1 常见集合</span></a></h3><ul><li>List：存储的元素有序，可重复。</li><li>Set：存储的元素不无序，不可重复。</li><li>Map：存储的元素不无序，不可重复。</li></ul><h4 id="_2-1-2-arraylist和linkedlist有什么区别" tabindex="-1"><a class="header-anchor" href="#_2-1-2-arraylist和linkedlist有什么区别"><span>2.1.2 ArrayList和LinkedList有什么区别？</span></a></h4><p>**（1）**数据结构不同</p><ul><li>ArrayList基于数组实现，默认初始化 10</li><li>LinkedList基于双向链表实现</li></ul><p>**（2）**用途不同</p><ul><li>多数情况下，ArrayList 更利于查找，LinkedList 更利于增删</li><li>注意，这里有个陷阱，LinkedList 更利于增删不是体现在时间复杂度上，因为二者增删的时间复杂度都是 O(n)，都需要遍历列表；而是体现在增删的效率上，因为 LinkedList 的增删只需要改变引用，而 ArrayList 的增删可能需要移动元素。</li></ul><h3 id="_2-2-集合线程安全" tabindex="-1"><a class="header-anchor" href="#_2-2-集合线程安全"><span>2.2 集合线程安全</span></a></h3><ul><li>使用 Vector 代替 ArrayList。（不推荐，Vector是一个历史遗留类）</li><li>使用 Collections.synchronizedList 包装 ArrayList，然后操作包装后的 list。</li><li>使用 CopyOnWriteArrayList 代替 ArrayList。</li><li>在使用 ArrayList 时，应用程序通过同步机制去控制 ArrayList 的读写。</li></ul><h2 id="_3-java-并发" tabindex="-1"><a class="header-anchor" href="#_3-java-并发"><span>3. Java 并发</span></a></h2><h3 id="_3-1-线程创建几种方式" tabindex="-1"><a class="header-anchor" href="#_3-1-线程创建几种方式"><span>3.1 线程创建几种方式</span></a></h3><p><img src="'+h+'" alt="img"></p><h3 id="_3-2-线程状态的切换" tabindex="-1"><a class="header-anchor" href="#_3-2-线程状态的切换"><span>3.2 线程状态的切换</span></a></h3><p><img src="'+u+'" alt="Java线程状态变化"></p><h3 id="_3-3-控制线程执行顺序" tabindex="-1"><a class="header-anchor" href="#_3-3-控制线程执行顺序"><span>3.3 控制线程执行顺序</span></a></h3><ul><li>以通过使用join()方法和CountDownLatch类来实现线程的顺序执行</li></ul><h3 id="_3-4-线程池" tabindex="-1"><a class="header-anchor" href="#_3-4-线程池"><span>3.4 线程池</span></a></h3><ul><li><p>核心参数</p><ul><li><p>corePoolSize：核心线程数</p></li><li><p>maximumPoolSize：最大线程数</p></li><li><p>keepAliveTime：非核心线程存货时间</p></li><li><p>unit：非核心线程存活时间单位</p></li><li><p>workQueud：等待队列</p></li><li><p>threadFactory：创建线程使用工厂</p></li><li><p>handler：饱和拒绝策略</p><ul><li>AbortPolicy ：直接抛出异常，默认使用此策略 <ul><li>CallerRunsPolicy：用调用者所在的线程来执行任务</li><li>DiscardOldestPolicy：丢弃阻塞队列里最老的任务，也就是队列里靠前的任务</li><li>DiscardPolicy ：当前任务直接丢弃</li></ul></li></ul></li></ul></li></ul><h3 id="_3-5-threadlocal-是什么" tabindex="-1"><a class="header-anchor" href="#_3-5-threadlocal-是什么"><span>3.5 ThreadLocal 是什么？</span></a></h3><ul><li><code>ThreadLocal</code>实现线程独立的方式是直接将值存放在<code>Thread</code>对象的<code>ThreadLocalMap</code>中，<code>Map</code>的<code>key</code>就是<code>ThreadLocal</code>的引用，且为了有助于<code>JVM</code>进行垃圾回收，<code>key</code>使用的是弱引用。在使用<code>ThreadLocal</code>后，一定要记得调用<code>remove</code>方法，有助于<code>JVM</code>对<code>value</code>的回收。</li></ul><h3 id="_3-6-锁" tabindex="-1"><a class="header-anchor" href="#_3-6-锁"><span>3.6 锁</span></a></h3><ul><li><p>synchronized</p><ul><li><p>用法</p><ul><li><strong>修饰实例方法:</strong> 作用于当前对象实例加锁，进入同步代码前要获得 <strong>当前对象实例的锁</strong></li><li><strong>修饰静态方法</strong></li><li><strong>修饰代码块</strong></li></ul></li><li><p>实现原理</p><ul><li>基于 JVM Monitor 同步工具</li></ul></li><li><p>synchronized怎么保证可见性？</p><ul><li>线程加锁前，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值。</li><li>线程加锁后，其它线程无法获取主内存中的共享变量。</li><li>线程解锁前，必须把共享变量的最新值刷新到主内存中。</li></ul></li><li><p>synchronized怎么保证有序性？</p><ul><li>synchronized同步的代码块，具有排他性，一次只能被一个线程拥有，所以synchronized保证同一时刻，代码是单线程执行的。</li></ul></li><li><p>synchronized怎么实现可重入的呢？</p><ul><li>synchronized 是可重入锁，也就是说，允许一个线程二次请求自己持有对象锁的临界资源，这种情况称为可重入锁。</li><li>synchronized 锁对象的时候有个计数器，他会记录下线程获取锁的次数，在执行完对应的代码块之后，计数器就会-1，直到计数器清零，就释放锁了。</li><li>之所以，是可重入的。是因为 synchronized 锁对象有个计数器，会随着线程获取锁后 +1 计数，当线程执行完毕后 -1，直到清零释放锁。</li></ul></li></ul></li><li><p>ReentrantLock</p><ul><li>ReentrantLock 实现原理 <ul><li>基于 API 通过 lock() 和 unlock() 加锁、解锁</li></ul></li></ul></li><li><p>synchronized 和 ReentrantLock 的区别</p></li></ul><p><img src="'+g+'" alt="synchronized和ReentrantLock的区别"></p><ul><li>死锁原因？如何避免？</li></ul><p><img src="'+_+'" alt="死锁示意图"></p><p><img src="'+m+'" alt="死锁产生必备四条件"></p><ul><li><strong>至少破坏死锁发生的一个条件</strong><ul><li>其中，互斥这个条件我们没有办法破坏，因为用锁为的就是互斥。不过其他三个条件都是有办法破坏掉的，到底如何做呢？</li><li>对于“请求并持有”这个条件，可以一次性请求所有的资源。</li><li>对于“不可剥夺”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。</li><li>对于“环路等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后就不存在环路了。</li></ul></li></ul><h2 id="_4-jvm" tabindex="-1"><a class="header-anchor" href="#_4-jvm"><span>4. JVM</span></a></h2><h3 id="_4-1-jmm" tabindex="-1"><a class="header-anchor" href="#_4-1-jmm"><span>4.1 JMM</span></a></h3><h3 id="_4-2-jvm-调优" tabindex="-1"><a class="header-anchor" href="#_4-2-jvm-调优"><span>4.2 JVM 调优</span></a></h3><p><img src="'+b+'" alt="JVM调优大致流程图"></p><p>实际上，JVM 调优是不得已而为之，有那功夫，好好把烂代码重构一下不比瞎调 JVM 强。</p><p>但是，面试官非要问怎么办？可以从处理问题的角度来回答（对应图中事后），这是一个中规中矩的案例：电商公司的运营后台系统，偶发性的引发 OOM 异常，堆内存溢出。</p><p>1）因为是偶发性的，所以第一次简单的认为就是堆内存不足导致，单方面的加大了堆内存从 4G 调整到 8G -Xms8g。</p><p>2）但是问题依然没有解决，只能从堆内存信息下手，通过开启了-XX:+HeapDumpOnOutOfMemoryError 参数 获得堆内存的 dump 文件。</p><p>3）用 JProfiler 对 堆 dump 文件进行分析，通过 JProfiler 查看到占用内存最大的对象是 String 对象，本来想跟踪着 String 对象找到其引用的地方，但 dump 文件太大，跟踪进去的时候总是卡死，而 String 对象占用比较多也比较正常，最开始也没有认定就是这里的问题，于是就从线程信息里面找突破点。</p><p>4）通过线程进行分析，先找到了几个正在运行的业务线程，然后逐一跟进业务线程看了下代码，有个方法引起了我的注意，<code>导出订单信息</code>。</p><p>5）因为订单信息导出这个方法可能会有几万的数据量，首先要从数据库里面查询出来订单信息，然后把订单信息生成 excel，这个过程会产生大量的 String 对象。</p><p>6）为了验证自己的猜想，于是准备登录后台去测试下，结果在测试的过程中发现导出订单的按钮前端居然没有做点击后按钮置灰交互事件，后端也没有做防止重复提交，因为导出订单数据本来就非常慢，使用的人员可能发现点击后很久后页面都没反应，然后就一直点，结果就大量的请求进入到后台，堆内存产生了大量的订单对象和 EXCEL 对象，而且方法执行非常慢，导致这一段时间内这些对象都无法被回收，所以最终导致内存溢出。</p><p>7）知道了问题就容易解决了，最终没有调整任何 JVM 参数，只是做了两个处理：</p><ul><li>在前端的导出订单按钮上加上了置灰状态，等后端响应之后按钮才可以进行点击</li><li>后端代码加分布式锁，做防重处理</li></ul><p>这样双管齐下，保证导出的请求不会一直打到服务端，问题解决！</p><h4 id="cpu-占用过高" tabindex="-1"><a class="header-anchor" href="#cpu-占用过高"><span>CPU 占用过高</span></a></h4><p><img src="'+v+'" alt="CPU飙高"></p><h4 id="内存泄漏" tabindex="-1"><a class="header-anchor" href="#内存泄漏"><span>内存泄漏</span></a></h4><p><img src="'+k+'" alt="内存泄漏可能原因"></p><h4 id="四种引用" tabindex="-1"><a class="header-anchor" href="#四种引用"><span>四种引用</span></a></h4><p><img src="'+E+'" alt="四种引用总结"></p><h3 id="_4-3-垃圾回收" tabindex="-1"><a class="header-anchor" href="#_4-3-垃圾回收"><span>4.3 垃圾回收</span></a></h3><ul><li>标记清除 <ul><li>执行效率不稳定</li><li>内存空间的碎片化问题</li></ul></li><li>标记复制 <ul><li>新生代垃圾收集主要采用这种算法，因为新生代的存活对象比较少，每次复制的只是少量的存活对象。当然，实际新生代的收集不是按照这个比例。</li></ul></li><li>标记整理 <ul><li>主要用于老年代，移动存活对象是个极为负重的操作，而且这种操作需要 Stop The World 才能进行，只是从整体的吞吐量来考量，老年代使用标记-整理算法更加合适。</li></ul></li></ul><h5 id="jvm-新生代怎么到老年代" tabindex="-1"><a class="header-anchor" href="#jvm-新生代怎么到老年代"><span>JVM 新生代怎么到老年代</span></a></h5><p><img src="'+f+'" alt="对象进入老年代"></p><h4 id="full-gc-触发条件" tabindex="-1"><a class="header-anchor" href="#full-gc-触发条件"><span>FULL GC 触发条件</span></a></h4><p><img src="'+x+'" alt="Full GC触发条件"></p><h3 id="_4-4-类加载" tabindex="-1"><a class="header-anchor" href="#_4-4-类加载"><span>4.4 类加载</span></a></h3><h2 id="" tabindex="-1"><a class="header-anchor" href="#"><span><img src="'+y+'" alt="Load Class"></span></a></h2><h4 id="_4-4-1-类加载器" tabindex="-1"><a class="header-anchor" href="#_4-4-1-类加载器"><span>4.4.1 类加载器</span></a></h4><ul><li><strong>启动类加载器</strong>(Bootstrap ClassLoader)用来加载 java 核心类库，无法被 java 程序直接引用。</li><li><strong>扩展类加载器</strong>(extensions class loader):它用来加载 Java 的扩展库。Java 虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载 Java 类。</li><li><strong>系统类加载器</strong>（system class loader）：它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 ClassLoader.getSystemClassLoader()来获取它。</li><li><strong>用户自定义类加载器</strong> (user class loader)，用户通过继承 java.lang.ClassLoader 类的方式自行实现的类加载器。</li></ul><h4 id="_4-4-2-双亲委派模型" tabindex="-1"><a class="header-anchor" href="#_4-4-2-双亲委派模型"><span>4.4.2 双亲委派模型</span></a></h4><h5 id="什么是双亲委派模型" tabindex="-1"><a class="header-anchor" href="#什么是双亲委派模型"><span>什么是双亲委派模型</span></a></h5><p>​ 双亲委派模型是描述类加载器之间的层次关系。它要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。（父子关系一般不会以继承的 关系实现，而是以组合关系来复用父加载器的代码）</p>',66),j={id:"工作过程",tabindex:"-1"},P={class:"header-anchor",href:"#工作过程"},q={href:"https://doocs.github.io/jvm/10-class-loader.html#%E5%B7%A5%E4%BD%9C%E8%BF%87%E7%A8%8B",target:"_blank",rel:"noopener noreferrer"},I=e("p",null,"​ 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此 所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（找不到所需的类）时，子加载器才会尝试自己去加 载。",-1),F=e("p",null,[l("​ 在 java.lang.ClassLoader 中的 "),e("code",null,"loadClass"),l(" 方法中实现该过程。")],-1),D={id:"为什么使用双亲委派模型",tabindex:"-1"},Q={class:"header-anchor",href:"#为什么使用双亲委派模型"},U={href:"https://doocs.github.io/jvm/10-class-loader.html#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B",target:"_blank",rel:"noopener noreferrer"},z=n(`<p>​ 像 java.lang.Object 这些存放在 rt.jar 中的类，无论使用哪个类加载器加载，最终都会委派给最顶端的启动类加载器加载，从而使得不同加载器加载的 Object 类都是同一个。</p><p>​ 相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，如果用户自己编写了一个称为 java.lang.Object 的类，并放在 classpath 下，那么系统将 会出现多个不同的 Object 类，Java 类型体系中最基础的行为也就无法保证。</p><h2 id="_5-设计模式" tabindex="-1"><a class="header-anchor" href="#_5-设计模式"><span>5. 设计模式</span></a></h2><ul><li>工厂模式 <ul><li>Spring 容器本质是一个大工厂，使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。</li></ul></li><li>代理模式 <ul><li>Spring AOP 功能功能就是通过代理模式来实现的，分为动态代理和静态代理。</li></ul></li><li>单例模式 <ul><li>Spring 中的 Bean 默认都是单例的，这样有利于容器对 Bean 的管理。</li></ul></li><li>模板模式 <ul><li>Spring 中 JdbcTemplate、RestTemplate 等以 Template 结尾的对数据库、网络等等进行操作的模板类，就使用到了模板模式。</li></ul></li><li>观察者模式 <ul><li>Spring 事件驱动模型就是观察者模式很经典的一个应用。</li></ul></li><li>适配器模式 <ul><li>Spring AOP 的增强或通知 (Advice) 使用到了适配器模式、Spring MVC 中也是用到了适配器模式适配 Controller。</li></ul></li><li>策略模式 <ul><li>Spring 中有一个 Resource 接口，它的不同实现类，会根据不同的策略去访问资源。</li></ul></li></ul><h2 id="_6-spring" tabindex="-1"><a class="header-anchor" href="#_6-spring"><span>6. Spring</span></a></h2><h3 id="_6-1-spring-bean-生命周期" tabindex="-1"><a class="header-anchor" href="#_6-1-spring-bean-生命周期"><span>6.1 Spring Bean 生命周期</span></a></h3><p>​ 实例化 - 属性赋值 - 初始化 - 使用 - 销毁</p><h3 id="_6-2-spring-boot-启动顺序" tabindex="-1"><a class="header-anchor" href="#_6-2-spring-boot-启动顺序"><span>6.2 Spring Boot 启动顺序</span></a></h3><p>​ 服务构建 - 环境准备 - 容器创建 - 填充容器</p><h3 id="_6-3-事务传播机制" tabindex="-1"><a class="header-anchor" href="#_6-3-事务传播机制"><span>6.3 事务传播机制</span></a></h3><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>PROPAGATION_REQUIRED —— 支持当前事务，如果当前没有事务，则新建一个事务，这是最常见的选择，也是 Spring 默认的一个事务传播属性。
PROPAGATION_SUPPORTS —— 支持当前事务，如果当前没有事务，则以非事务方式执行。
PROPAGATION_MANDATORY —— 支持当前事务，如果当前没有事务，则抛出异常。
PROPAGATION_REQUIRES_NEW —— 新建事务，如果当前存在事务，把当前事务挂起。
PROPAGATION_NOT_SUPPORTED —— 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
PROPAGATION_NEVER —— 以非事务方式执行，如果当前存在事务，则抛出异常。
PROPAGATION_NESTED —— Nested 的事务和它的父事务是相依的，它的提交是要等和它的父事务一块提交的。
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_6-4-事务可能失效原因" tabindex="-1"><a class="header-anchor" href="#_6-4-事务可能失效原因"><span>6.4 事务可能失效原因</span></a></h3><ul><li>@Transactional 应用在非 public 修饰的方法上</li><li>@Transactional 注解属性 propagation(传播机制) 设置错误</li><li>@Transactional 注解属性 rollbackFor 设置错误</li><li>同一个类中方法调用，导致@Transactional 失效</li></ul><h3 id="_6-5-解决循环依赖" tabindex="-1"><a class="header-anchor" href="#_6-5-解决循环依赖"><span>6.5 解决循环依赖</span></a></h3><table><thead><tr><th style="text-align:left;">方式</th><th style="text-align:left;">依赖情况</th><th style="text-align:left;">注入方式</th><th style="text-align:left;">能够解决循环依赖</th></tr></thead><tbody><tr><td style="text-align:left;">情况一</td><td style="text-align:left;">AB相互依赖</td><td style="text-align:left;">均采用setter方式</td><td style="text-align:left;">能</td></tr><tr><td style="text-align:left;">情况二</td><td style="text-align:left;">AB相互依赖</td><td style="text-align:left;">均采用构造器方式</td><td style="text-align:left;">不能</td></tr><tr><td style="text-align:left;">情况三</td><td style="text-align:left;">AB相互依赖</td><td style="text-align:left;">A中注入B采用setter，B中注入A采用构造器</td><td style="text-align:left;">能</td></tr><tr><td style="text-align:left;">情况四</td><td style="text-align:left;">AB相互依赖</td><td style="text-align:left;">A中注入B采用构造器，B中注入A采用setter</td><td style="text-align:left;">不能</td></tr><tr><td style="text-align:left;">情况五</td><td style="text-align:left;">AB相互依赖</td><td style="text-align:left;">A中注入B采用<code>@Autowired</code>，B中注入A采用<code>@PostConstruct</code> + setter</td><td style="text-align:left;">能</td></tr><tr><td style="text-align:left;">情况六</td><td style="text-align:left;">AB相互依赖</td><td style="text-align:left;">A中注入B采用<code>@PostConstruct</code> + setter，B中注入A采用<code>@Autowired</code></td><td style="text-align:left;">能</td></tr></tbody></table><h3 id="_6-6-spring-cloud-spring-cloud-alibaba-常用组件" tabindex="-1"><a class="header-anchor" href="#_6-6-spring-cloud-spring-cloud-alibaba-常用组件"><span>6.6 Spring Cloud/Spring Cloud Alibaba 常用组件</span></a></h3><ul><li><p>服务注册中心</p><ul><li>Eureka：Spring Cloud原生自带（停更）</li><li>Zookeeper：Eureka替换，旧技术</li><li>Consul：go语言写的</li><li>Nacos：百万级客户使用，完美替换Eureka（推荐使用） <ul><li>随机算法</li><li>轮询算法</li><li>最少活跃算法</li><li>一致性哈希算法</li><li>加权轮询算法</li><li>加权最少活跃算法</li></ul></li></ul><table><thead><tr><th></th><th>Nacos</th><th>Eureka</th><th>Cosul</th><th>Zookeeper</th></tr></thead><tbody><tr><td>一致性协议</td><td>CP+AP</td><td>AP</td><td>CP</td><td>CP</td></tr><tr><td>健康检查</td><td>TCP/HTTP/MYSQL/Client Beat</td><td>Client Beat</td><td>TCP/HTTP/gRPC/Cmd</td><td>Keep Alive</td></tr><tr><td>负载均衡策略</td><td>权重/metadata/Selector</td><td>Ribbon</td><td>Fabio</td><td></td></tr><tr><td>雪崩保护</td><td>有</td><td>有</td><td>无</td><td>无</td></tr><tr><td>自动注销实例</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>访问协议</td><td>HTTP/DNS</td><td>HTTP</td><td>HTTP/DNS</td><td>TCP</td></tr><tr><td>监听支持</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>多数据中心</td><td>支持</td><td>支持</td><td>支持</td><td>不支持</td></tr><tr><td>跨注册中心同步</td><td>支持</td><td>不支持</td><td>支持</td><td>不支持</td></tr><tr><td>SpringCloud集成</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>Dubbo集成</td><td>支持</td><td>不支持</td><td>支持</td><td>支持</td></tr><tr><td>K8S集成</td><td>支持</td><td>不支持</td><td>支持</td><td>不支持</td></tr></tbody></table></li><li><p>服务调用</p><ul><li><p>Ribbon：继续使用（停止更新，进入维护阶段）</p></li><li><p>LoadBalancer：慢慢替换Ribbon</p></li><li><p>Feign：X</p></li><li><p>OpenFeign：Spring公司自己开发的</p></li><li><p>Dubbo：RPC调用</p></li><li><p>如何自己设计一个类似 Dubbo 的 RPC 框架</p><ul><li><p>上来你的服务就得去注册中心注册吧，你是不是得有个注册中心，保留各个服务的信息，可以用 zookeeper 来做，对吧。</p></li><li><p>然后你的消费者需要去注册中心拿对应的服务信息吧，对吧，而且每个服务可能会存在于多台机器上。</p></li><li><p>接着你就该发起一次请求了，咋发起？当然是基于动态代理了，你面向接口获取到一个动态代理，这个动态代理就是接口在本地的一个代理，然后这个代理会找到服务对应的机器地址。</p></li><li><p>然后找哪个机器发送请求？那肯定得有个负载均衡算法了，比如最简单的可以随机轮询是不是。</p></li><li><p>接着找到一台机器，就可以跟它发送请求了，第一个问题咋发送？你可以说用 netty 了，nio 方式；第二个问题发送啥格式数据？你可以说用 hessian 序列化协议了，或者是别的，对吧。然后请求过去了。</p></li><li><p>服务器那边一样的，需要针对你自己的服务生成一个动态代理，监听某个网络端口了，然后代理你本地的服务代码。接收到请求的时候，就调用对应的服务代码，对吧。</p></li></ul></li></ul></li><li><p>服务熔断与降级</p><ul><li><p>Hystrix：企业大规模使用，官网不推荐</p></li><li><p>Resilience4j：国外大规模使用，替换Hystrix</p></li><li><p>Sentienl：国内推荐Sentienl，替换Hystrix</p><table><thead><tr><th></th><th>Sentienl</th><th>Hystrix</th><th>Resilience4j</th></tr></thead><tbody><tr><td>隔离策略</td><td>信号量隔离（并发线程数限流）</td><td>线程池隔离/信号量隔离</td><td>信号量隔离</td></tr><tr><td>熔断降级策略</td><td>基于响应时间、异常比率、异常数</td><td>基于异常比率</td><td>基于异常比率、响应时间</td></tr><tr><td>实时统计实现</td><td>滑动窗口（LeapArray）</td><td>滑动窗口（基于 RxJava）</td><td>Ring Bit Buffer</td></tr><tr><td>动态规则配置</td><td>支持多种数据源</td><td>支持多种数据源</td><td>有限支持</td></tr><tr><td>扩展性</td><td>多个扩展点</td><td>插件的形式</td><td>接口的形式</td></tr><tr><td>基于注解的支持</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>限流</td><td>基于 QPS，支持基于调用关系的限流</td><td>有限的支持</td><td>Rate Limiter</td></tr><tr><td>流量整形</td><td>支持预热模式、匀速器模式、预热排队模式</td><td>不支持</td><td>简单的 Rate Limiter 模式</td></tr><tr><td>系统自适应保护</td><td>支持</td><td>不支持</td><td>不支持</td></tr><tr><td>控制台</td><td>提供开箱即用的控制台，可配置规则、查看秒级监控、机器发现等</td><td>简单的监控查看</td><td>不提供控制台，可对接其它监控系统</td></tr></tbody></table></li></ul></li><li><p>服务网关 Spring Cloud Gateway</p><ol><li><strong>路由转发</strong>：基于Spring WebFlux的RouterFunctions，支持各种Predicate（路由匹配条件）和Filter（过滤器）。</li><li><strong>动态路由</strong>：可以在运行时动态添加路由信息，不需要重启服务。</li><li><strong>负载均衡</strong>：集成了Spring Cloud的服务发现和负载均衡，可以直接使用服务名进行路由转发。</li><li><strong>认证授权</strong>：可以集成Spring Security进行统一的认证和授权管理。</li><li><strong>限流熔断</strong>：集成了Spring Cloud Circuit Breaker，可以实现服务级别的熔断，同时集成了RequestRateLimiter，可以实现接口级别的限流。</li><li><strong>监控</strong>：集成了Spring Boot Actuator，可以对网关的运行情况进行监控</li></ol></li><li><p>服务配置</p><ul><li>spring cloud config：不在使用</li><li>apollo</li><li>Nacos：推荐</li></ul></li><li><p>服务总线</p><p>在微服务架构的系统中，通常会使用轻量级的消息代理来构建一个<strong>共用的消息主题</strong>，并让系统中所有微服务实例都连接上来，由于该主题中产生的消息会被所有实例监听和消费，所以称它为消息总线。在总线上的各个实例，都可以方便地广播一些需要让其他连接在该主题上的实例都知道的消息。</p><ul><li>Bus：不推荐</li><li>Nacos：推荐</li></ul></li><li><p>链路追踪</p><ul><li>sleuth</li><li>skywalking</li></ul></li><li><p>鉴权</p><ul><li>spring security</li><li>JWT</li></ul></li><li><p>分布式事务</p><ul><li>seata</li></ul></li><li><p>服务监控</p><ul><li>Spring Admin</li><li>普罗米修斯</li></ul></li></ul><h2 id="_7-mysql" tabindex="-1"><a class="header-anchor" href="#_7-mysql"><span>7. <em>Mysql</em></span></a></h2><h3 id="_7-1-存储引擎" tabindex="-1"><a class="header-anchor" href="#_7-1-存储引擎"><span>7.1 存储引擎</span></a></h3><ul><li>InnoDB <ul><li>事务型存储引擎</li><li>四个标准隔离级别</li><li>主索引是聚簇索引</li><li>支持真正的在线热备份</li><li>支持表跟行级锁</li><li>支持外键</li></ul></li><li>MyISAM <ul><li>不支持事务</li><li>不支持行级锁</li><li>崩溃恢复: MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢</li><li>其它特性: MyISAM 支持压缩表和空间数据索引</li></ul></li></ul><h3 id="_7-2-隔离级别" tabindex="-1"><a class="header-anchor" href="#_7-2-隔离级别"><span>7.2 隔离级别</span></a></h3><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>DEFAULT 这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别.
未提交读 (read uncommited) :脏读，不可重复读，虚读都有可能发生
已提交读 (read commited):避免脏读。但是不可重复读和虚读有可能发生
可重复读 (repeatable read) :避免脏读和不可重复读.但是虚读有可能发生.
串行化的 (serializable) :避免以上所有读问题.
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-执行一条-sql-查询语句-期间发生了什么" tabindex="-1"><a class="header-anchor" href="#_7-3-执行一条-sql-查询语句-期间发生了什么"><span>7.3 执行一条 SQL 查询语句，期间发生了什么？</span></a></h3><ul><li>连接器：建立连接，管理连接、校验用户身份；</li><li>查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；</li><li>解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；</li><li>执行 SQL：执行 SQL 共有三个阶段： <ul><li>预处理阶段：检查表或字段是否存在；将 <code>select *</code> 中的 <code>*</code> 符号扩展为表上的所有列。</li><li>优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；</li><li>执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；</li></ul></li></ul><p><img src="`+A+'" alt="查询语句执行流程"></p><h3 id="_7-4-mysql-一行记录是怎么存储的" tabindex="-1"><a class="header-anchor" href="#_7-4-mysql-一行记录是怎么存储的"><span>7.4 MySQL 一行记录是怎么存储的？</span></a></h3><p><img src="'+B+`" alt="img"></p><ul><li><p>MySQL 的 NULL 值是怎么存放的？</p><ul><li><p>MySQL 的 Compact 行格式中会用「NULL值列表」来标记值为 NULL 的列，NULL 值并不会存储在行格式中的真实数据部分。</p></li><li><p>NULL值列表会占用 1 字节空间，当表中所有字段都定义成 NOT NULL，行格式中就不会有 NULL值列表，这样可节省 1 字节的空间。</p></li></ul></li><li><p>MySQL 怎么知道 varchar(n) 实际占用数据的大小？</p><ul><li>MySQL 的 Compact 行格式中会用「变长字段长度列表」存储变长字段实际占用的数据大小。</li></ul></li><li><p>varchar(n) 中 n 最大取值为多少？</p><ul><li><p>一行记录最大能存储 65535 字节的数据，但是这个是包含「变长字段字节数列表所占用的字节数」和「NULL值列表所占用的字节数」。所以， 我们在算 varchar(n) 中 n 最大值时，需要减去这两个列表所占用的字节数。</p></li><li><p>如果一张表只有一个 varchar(n) 字段，且允许为 NULL，字符集为 ascii。varchar(n) 中 n 最大取值为 65532。</p></li><li><p>计算公式：65535 - 变长字段字节数列表所占用的字节数 - NULL值列表所占用的字节数 = 65535 - 2 - 1 = 65532。</p></li><li><p>如果有多个字段的话，要保证所有字段的长度 + 变长字段字节数列表所占用的字节数 + NULL值列表所占用的字节数 &lt;= 65535。</p></li></ul></li><li><p>行溢出后，MySQL 是怎么处理的？</p><ul><li><p>如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。</p></li><li><p>Compact 行格式针对行溢出的处理是这样的：当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。</p></li><li><p>Compressed 和 Dynamic 这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页。而实际的数据都存储在溢出页中。</p></li></ul></li></ul><h3 id="_7-5-sql-优化" tabindex="-1"><a class="header-anchor" href="#_7-5-sql-优化"><span>7.5 SQL 优化</span></a></h3><h4 id="_7-5-1-深分页问题" tabindex="-1"><a class="header-anchor" href="#_7-5-1-深分页问题"><span>7.5.1 深分页问题</span></a></h4><p><code>limit</code>深分页问题，会导致慢查询，应该大家都司空见惯了吧。</p><p><strong>limit深分页为什么会变慢呢？</strong> 假设有表结构如下：</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>CREATE TABLE account (
  id int(11) NOT NULL AUTO_INCREMENT COMMENT &#39;主键Id&#39;,
  name varchar(255) DEFAULT NULL COMMENT &#39;账户名&#39;,
  balance int(11) DEFAULT NULL COMMENT &#39;余额&#39;,
  create_time datetime NOT NULL COMMENT &#39;创建时间&#39;,
  update_time datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;更新时间&#39;,
  PRIMARY KEY (id),
  KEY idx_name (name),
  KEY idx_create_time (create_time) //索引
) ENGINE=InnoDB AUTO_INCREMENT=1570068 DEFAULT CHARSET=utf8 ROW_FORMAT=REDUNDANT COMMENT=&#39;账户表&#39;;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>以下这个SQL，你知道执行过程是怎样的呢？</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>select id,name,balance from account where create_time&gt; &#39;2020-09-19&#39; limit 100000,10;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>这个SQL的执行流程酱紫：</p><ol><li>通过普通二级索引树 <code>idx_create_time</code>，过滤 <code>create_time</code>条件，找到满足条件的主键 <code>id</code>。</li><li>通过主键 <code>id</code>，回到 <code>id</code>主键索引树，找到满足记录的行，然后取出需要展示的列（回表过程）</li><li>扫描满足条件的 <code>100010</code>行，然后扔掉前 <code>100000</code>行，返回。</li></ol><p><img src="`+L+`" alt="img"></p><p>因此，limit深分页，导致SQL变慢原因有两个：</p><ul><li><code>limit</code>语句会先扫描 <code>offset+n</code>行，然后再丢弃掉前 <code>offset</code>行，返回后 <code>n</code>行数据。也就是说 <code>limit 100000,10</code>，就会扫描 <code>100010</code>行，而 <code>limit 0,10</code>，只扫描 <code>10</code>行。</li><li><code>limit 100000,10</code> 扫描更多的行数，也意味着回表更多的次数。</li></ul><p><strong>如何优化深分页问题?</strong></p><p>我们可以通过减少回表次数来优化。一般有<strong>标签记录法和延迟关联法</strong>。</p><p><strong>标签记录法</strong></p><blockquote><p>就是标记一下上次查询到哪一条了，下次再来查的时候，从该条开始往下扫描。就好像看书一样，上次看到哪里了，你就折叠一下或者夹个书签，下次来看的时候，直接就翻到啦。</p></blockquote><p>假设上一次记录到<code>100000</code>，则SQL可以修改为：</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>select  id,name,balance FROM account where id &gt; 100000 limit 10;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>这样的话，后面无论翻多少页，性能都会不错的，因为命中了id索引。但是这种方式有局限性：需要一种类似连续自增的字段。</p><p><strong>延迟关联法</strong></p><p>延迟关联法，就是把条件转移到<strong>主键索引树</strong>，然后减少回表。如下</p><div class="language-text line-numbers-mode" data-ext="text" data-title="text"><pre class="language-text"><code>select  acct1.id,acct1.name,acct1.balance FROM account acct1 INNER JOIN (SELECT a.id FROM account a WHERE a.create_time &gt; &#39;2020-09-19&#39; limit 100000, 10) AS acct2 on acct1.id= acct2.id;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><strong>优化思路</strong>就是，先通过<code>idx_create_time</code>二级索引树查询到满足条件的<code>主键ID</code>，再与原表通过<code>主键ID</code>内连接，这样后面直接走了主键索引了，同时也减少了回表。</p><h5 id="范围查询" tabindex="-1"><a class="header-anchor" href="#范围查询"><span>范围查询</span></a></h5><p>当可以保证ID的连续性时，用户根据ID范围进行分页是比较好的解决方案：</p><div class="language-vbnet line-numbers-mode" data-ext="vbnet" data-title="vbnet"><pre class="language-vbnet"><code><span class="token keyword">SELECT</span> <span class="token operator">*</span> FROM t_order WHERE id <span class="token operator">&gt;</span> <span class="token number">100000</span> <span class="token keyword">AND</span> id <span class="token operator">&lt;=</span> <span class="token number">100010</span> ORDER BY id
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>或通过记录上次查询结果的最后一条记录的ID进行下一页的查询：</p><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="language-sql"><code><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> t_order <span class="token keyword">WHERE</span> id <span class="token operator">&gt;</span> <span class="token number">100000</span> <span class="token keyword">LIMIT</span> <span class="token number">10</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h5 id="子查询" tabindex="-1"><a class="header-anchor" href="#子查询"><span>子查询</span></a></h5><p>把查询条件，转移回到主键索引。由于子查询中只获取主键列对应的值，可以一定程度上降低应用OOM风险。</p><p>改写后的SQL为（id为表t_order的主键）：</p><div class="language-sql line-numbers-mode" data-ext="sql" data-title="sql"><pre class="language-sql"><code><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> t_order <span class="token keyword">WHERE</span> id <span class="token operator">&gt;=</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> id <span class="token keyword">FROM</span> t_order <span class="token keyword">limit</span> <span class="token number">1000000</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">LIMIT</span> <span class="token number">10</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><strong>数据量过大时，客户端仍有OOM风险，建议把子查询仅作为应急过渡方案。</strong></p><h4 id="_7-5-2-大数据表处理" tabindex="-1"><a class="header-anchor" href="#_7-5-2-大数据表处理"><span>7.5.2 大数据表处理</span></a></h4><p>处理大数据表主要有以下几种方式：</p><ol><li><strong>分区</strong>：使用分区将大数据表分解成较小、更易于管理的部分。每个分区可以独立存储，单独进行查询、备份和恢复等操作，这有助于提高查询性能和数据管理效率。</li><li><strong>分表/分片</strong>：对于大访问量并且表数据比较多的表，可以采取分表和分区结合的方式。将大表拆分为多个小表，这样可以提高查询和插入等操作的效率。</li><li><strong>归档</strong>：对于一些老旧或不常用的数据，可以将其归档，这样可以提高查询性能，减少存储空间。</li><li><strong>优化查询</strong>：优化查询语句，尽量避免进行全表查询。优化子查询，尽量使用join来代替子查询，这样可以提高查询效率。</li><li><strong>使用索引</strong>：对于经常进行查询的字段，可以创建索引，加快查询速度。</li><li><strong>使用大数据框架</strong>：例如 Hadoop，Spark 等大数据处理框架，针对海量数据进行离线分析和处理。</li><li><strong>构建数据湖</strong>：当查询和分析需求复杂且数据规模庞大时，可以考虑将数据注入到构建的数据湖中。数据湖能够存储大量的原始数据，支持多种数据分析工具直接在数据湖上进行复杂的数据分析，提高了数据查询的效率。</li></ol><p>以上这些方案可以结合实际情况和需求来选择使用。 更多细节和例子，可以参考以下链接:</p>`,65),J={href:"https://juejin.cn/post/7146016771936354312",target:"_blank",rel:"noopener noreferrer"},V={href:"https://zhuanlan.zhihu.com/p/108383420",target:"_blank",rel:"noopener noreferrer"},H={href:"https://cn.pingcap.com/article/post/3865.html",target:"_blank",rel:"noopener noreferrer"},G={href:"https://aws.amazon.com/cn/blogs/china/injecting-a-billion-level-database-into-amazon-s3-data-lake/",target:"_blank",rel:"noopener noreferrer"},W=e("h2",{id:"_8-redis",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_8-redis"},[e("span",null,[l("8. "),e("em",null,"Redis")])])],-1),Y=e("h3",{id:"_8-1-分布式锁",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_8-1-分布式锁"},[e("span",null,"8.1 分布式锁")])],-1),K=e("li",null,[l('这个主要利用redis的setnx命令进行，setnx："set if not exists"就是如果不存在则成功设置缓存同时返回1，否则返回0 ，这个特性在很多后台中都有所运用，因为我们服务器是集群的，定时任务可能在两台机器上都会运行，所以在定时任务中首先 通过setnx设置一个lock，'),e("br"),l(" 如果成功设置则执行，如果没有成功设置，则表明该定时任务已执行。 当然结合具体业务，我们可以给这个lock加一个过期时间，比如说30分钟执行一次的定时任务，那么这个过期时间设置为小于30分钟的一个时间就可以，这个与定时任务的周期以及定时任务执行消耗时间相关。")],-1),X=e("li",null,[l("实现 "),e("ul",null,[e("li",null,"单个Redis实例：setnx(key,当前时间+过期时间) + Lua"),e("li",null,"Redis集群模式：Redlock")])],-1),Z=e("li",null,"借助 Redis 实现分布式锁时，有一个共同的缺陷: 当获取锁被拒绝后，需要不断的循环，重新发送获取锁(创建 key )的请求，直到请求成功。这就造成空转，浪费宝贵的 CPU 资源。",-1),$={href:"https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html",target:"_blank",rel:"noopener noreferrer"},ee={href:"http://antirez.com/news/101",target:"_blank",rel:"noopener noreferrer"},le=n(`<h3 id="_8-2-缓存" tabindex="-1"><a class="header-anchor" href="#_8-2-缓存"><span>8.2 缓存</span></a></h3><ul><li>缓存穿透 <ul><li>缓存穿透是指缓存和数据库中都没有的数据</li><li>解决： <ul><li>接口层增加校验</li><li>从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null</li><li>布隆过滤器</li></ul></li></ul></li><li>缓存击穿 <ul><li>缓存击穿是指缓存中没有但数据库中有的数据(一般是缓存时间到期)</li><li>解决： <ul><li>设置热点数据永远不过期</li><li>接口限流与熔断，降级</li><li>加互斥锁</li></ul></li></ul></li><li>缓存雪崩 <ul><li>缓存雪崩是指缓存中数据大批量到过期时间</li><li>解决： <ul><li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生</li><li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中</li><li>设置热点数据永远不过期</li></ul></li></ul></li></ul><h3 id="_8-3-持久化" tabindex="-1"><a class="header-anchor" href="#_8-3-持久化"><span>8.3 持久化</span></a></h3><ul><li>RDB 与 AOF 混合</li></ul><h3 id="_8-4-高可用" tabindex="-1"><a class="header-anchor" href="#_8-4-高可用"><span>8.4 高可用</span></a></h3><ul><li>集群部署</li></ul><h3 id="_8-5-过期策略" tabindex="-1"><a class="header-anchor" href="#_8-5-过期策略"><span>8.5 过期策略</span></a></h3><ul><li><p>Redis 过期策略是：<strong>定期删除+惰性删除</strong>。</p></li><li><p>Redis 内存淘汰机制有以下几个：</p><ul><li>noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。</li><li><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，移除最近最少使用的 key（这个是<strong>最常用</strong>的）。</li><li>allkeys-random：当内存不足以容纳新写入数据时，在<strong>键空间</strong>中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。</li><li>volatile-lru：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，移除最近最少使用的 key（这个一般不太合适）。</li><li>volatile-random：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，<strong>随机移除</strong>某个 key。</li><li>volatile-ttl：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间</strong>中，有<strong>更早过期时间</strong>的 key 优先移除。</li></ul></li><li><p>LRU 就是 Least Recently Used 的缩写，翻译过来就是“最近最少使用”。也就是说 LRU 算法会将最近最少用的缓存移除，让给最新使用的缓存。而往往最常读取的，也就是读取次数最多的，所以利用好 LRU 算法，我们能够提供对热点数据的缓存效率，能够提高缓存服务的内存使用率。</p><div class="language-java line-numbers-mode" data-ext="java" data-title="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LRUCache</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span> <span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">extends</span> <span class="token class-name">LinkedHashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span> <span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>
    <span class="token keyword">private</span> <span class="token keyword">int</span> capacity<span class="token punctuation">;</span>

    <span class="token doc-comment comment">/**
     * 传递进来最多能缓存多少数据
     *
     * <span class="token keyword">@param</span> <span class="token parameter">capacity</span> 缓存大小
     */</span>
    <span class="token keyword">public</span> <span class="token class-name">LRUCache</span><span class="token punctuation">(</span><span class="token keyword">int</span> capacity<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">super</span><span class="token punctuation">(</span>capacity<span class="token punctuation">,</span> <span class="token number">0.75f</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">this</span><span class="token punctuation">.</span>capacity <span class="token operator">=</span> capacity<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token doc-comment comment">/**
     * 如果map中的数据量大于设定的最大容量，返回true，再新加入对象时删除最老的数据
     *
     * <span class="token keyword">@param</span> <span class="token parameter">eldest</span> 最老的数据项
     * <span class="token keyword">@return</span> true则移除最老的数据
     */</span>
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">protected</span> <span class="token keyword">boolean</span> <span class="token function">removeEldestEntry</span><span class="token punctuation">(</span><span class="token class-name">Map<span class="token punctuation">.</span>Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span> <span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> eldest<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 当 map中的数据量大于指定的缓存个数的时候，自动移除最老的数据</span>
        <span class="token keyword">return</span> <span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> capacity<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><h2 id="_9-mq" tabindex="-1"><a class="header-anchor" href="#_9-mq"><span>9. <em>MQ</em></span></a></h2><h3 id="_9-1-为什么使用消息队列" tabindex="-1"><a class="header-anchor" href="#_9-1-为什么使用消息队列"><span>9.1 为什么使用消息队列</span></a></h3>`,10),te=e("li",null,[l("优点 "),e("ul",null,[e("li",null,[e("strong",null,"解耦"),l("、"),e("strong",null,"异步"),l("、"),e("strong",null,"削峰")])])],-1),ae=e("li",null,[l("系统可用性降低 "),e("ul",null,[e("li",null,"镜像集群")])],-1),ne={href:"https://doocs.github.io/advanced-java/#/docs/high-concurrency/how-to-ensure-that-messages-are-not-repeatedly-consumed",target:"_blank",rel:"noopener noreferrer"},ie=e("ul",null,[e("li",null,"比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。"),e("li",null,"比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。"),e("li",null,"比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。"),e("li",null,"比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。")],-1),se={href:"https://doocs.github.io/advanced-java/#/docs/high-concurrency/how-to-ensure-the-reliable-transmission-of-messages",target:"_blank",rel:"noopener noreferrer"},de=n("<ul><li>生产者 confirm 模式 （异步） <ul><li>所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 <code>confirm</code> 模式，在生产者那里设置开启 <code>confirm</code> 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 <code>ack</code> 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 <code>nack</code> 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</li></ul></li><li>持久化</li><li>消费者关闭自动 ack</li></ul>",1),re=e("li",null,"一致性问题",-1),oe=n('<h3 id="_9-2-如何设计一个消息队列" tabindex="-1"><a class="header-anchor" href="#_9-2-如何设计一个消息队列"><span>9.2 如何设计一个消息队列</span></a></h3><ul><li>首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -&gt; topic -&gt; partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？</li><li>其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。</li><li>其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -&gt; leader &amp; follower -&gt; broker 挂了重新选举 leader 即可对外服务。</li><li>能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。</li></ul><h3 id="_9-3-处理大量积压消息" tabindex="-1"><a class="header-anchor" href="#_9-3-处理大量积压消息"><span>9.3 处理大量积压消息</span></a></h3><ul><li>提高消费并行度</li><li>批量方式消费</li><li>跳过非重要消息</li><li>优化每条消息消费过程</li></ul><h3 id="_9-4-消息丢失原因及-rabbitmq-应对方案" tabindex="-1"><a class="header-anchor" href="#_9-4-消息丢失原因及-rabbitmq-应对方案"><span>9.4 消息丢失原因及 RabbitMQ 应对方案</span></a></h3><ol><li>生产者发送消息到 MQ 有可能丢失消息</li><li>MQ 收到消息后写入硬盘可能丢失消息 <ol><li>数据存盘绕过缓存，改为同步刷盘，这一步需要修改 Broker 的配置文件，将 flushDiskType 改为 SYNC_FLUSH 同步刷盘策略，默认的是 ASYNC_FLUSH 异步刷盘，一旦同步刷盘返回成功，那么就一定保证消息已经持久化到磁盘中了。</li></ol></li><li>消息写入硬盘后，硬盘坏了丢失消息 <ol><li>为了保证磁盘损坏导致丢失数据，RocketMQ 采用主从机构，集群部署，Leader 中的数据在多个 Follower 中都存有备份，防止单点故障导致数据丢失。</li></ol></li><li>消费者消费 MQ 也可能丢失消息</li><li>整个 MQ 节点挂了丢失消息</li></ol><p><img src="'+w+'" alt="rabbitmq-message-lose-solution"></p><h3 id="_9-5-队列模式" tabindex="-1"><a class="header-anchor" href="#_9-5-队列模式"><span>9.5 队列模式</span></a></h3><ul><li><p>简单<strong>模式</strong> 代码实现</p></li><li><p>工作<strong>模式</strong> 代码实现 轮询分发(round-robin) 公平分发(fair dipatch)</p></li><li><p>发布订阅<strong>模式</strong> 代码实现</p></li><li><p>路由<strong>模式</strong>(精确匹配) 代码实现</p></li><li><p>Topic<strong>模式</strong>(模糊匹配)</p><p><img src="'+S+'" alt="主题模式(Topics)"></p><h4 id="主题交换机方式接收消息-将routing-key和模式进行匹配。" tabindex="-1"><a class="header-anchor" href="#主题交换机方式接收消息-将routing-key和模式进行匹配。"><span>主题交换机方式接收消息，将routing key和模式进行匹配。</span></a></h4><h4 id="多消费者-选择性多队列-每个队列通过模式匹配。" tabindex="-1"><a class="header-anchor" href="#多消费者-选择性多队列-每个队列通过模式匹配。"><span>多消费者，选择性多队列，每个队列通过模式匹配。</span></a></h4><blockquote><p>队列需要绑定在一个模式上。<br> #匹配一个词或多个词，*只匹配一个词。</p></blockquote><p>应用场景：</p><blockquote><p>iphone促销活动可以接收主题为多种iPhone的消息，如iphone12、iphone13等。</p></blockquote></li></ul><h2 id="_10-分布式" tabindex="-1"><a class="header-anchor" href="#_10-分布式"><span>10. <em>分布式</em></span></a></h2><h3 id="跨服务之间分页查询实现及大量数据导出情况" tabindex="-1"><a class="header-anchor" href="#跨服务之间分页查询实现及大量数据导出情况"><span>跨服务之间分页查询实现及大量数据导出情况</span></a></h3><ul><li>个人实际经历是针对当前服务为主体进行查询，遍历获取对应的 id，然后 RPC 调用其它服务通过 id 去获取数据集合，再对其进行封装。</li><li>针对导出需要查询大量数据的情况，则是采取服务端生成形式。</li></ul>',12),ce={id:"分库分表实现",tabindex:"-1"},pe={class:"header-anchor",href:"#分库分表实现"},he={href:"https://www.pdai.tech/md/framework/ds-sharding/sharding-x-arch.html",target:"_blank",rel:"noopener noreferrer"},ue={id:"分布式锁实现",tabindex:"-1"},ge={class:"header-anchor",href:"#分布式锁实现"},_e={href:"https://www.pdai.tech/md/arch/arch-z-lock.html#%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F---%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%8F%8A%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88",target:"_blank",rel:"noopener noreferrer"},me={href:"https://www.pdai.tech/md/arch/arch-z-lock.html#%E5%9F%BA%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%9C%89%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7",target:"_blank",rel:"noopener noreferrer"},be={href:"https://www.pdai.tech/md/arch/arch-z-lock.html#%E5%9F%BA%E4%BA%8Eredis%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%9C%89%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7",target:"_blank",rel:"noopener noreferrer"},ve=e("ul",null,[e("li",null,"参照上面Redis知识整理")],-1),ke={href:"https://www.pdai.tech/md/arch/arch-z-lock.html#%E5%9F%BA%E4%BA%8Ezookeeper%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81",target:"_blank",rel:"noopener noreferrer"},Ee={id:"分布式-id-实现",tabindex:"-1"},fe={class:"header-anchor",href:"#分布式-id-实现"},xe={href:"https://www.pdai.tech/md/arch/arch-z-id.html#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%85%A8%E5%B1%80%E5%94%AF%E4%B8%80id",target:"_blank",rel:"noopener noreferrer"},ye={href:"https://www.pdai.tech/md/arch/arch-z-id.html#uuid",target:"_blank",rel:"noopener noreferrer"},Ae={href:"https://www.pdai.tech/md/arch/arch-z-id.html#%E6%95%B0%E6%8D%AE%E5%BA%93%E7%94%9F%E6%88%90",target:"_blank",rel:"noopener noreferrer"},Be={href:"https://www.pdai.tech/md/arch/arch-z-id.html#%E4%BD%BF%E7%94%A8redis%E5%AE%9E%E7%8E%B0",target:"_blank",rel:"noopener noreferrer"},Le={href:"https://www.pdai.tech/md/arch/arch-z-id.html#%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95-snowflake",target:"_blank",rel:"noopener noreferrer"},we={href:"https://www.pdai.tech/md/arch/arch-z-id.html#%E7%99%BE%E5%BA%A6-uidgenerator",target:"_blank",rel:"noopener noreferrer"},Se={href:"https://www.pdai.tech/md/arch/arch-z-id.html#%E7%BE%8E%E5%9B%A2leaf",target:"_blank",rel:"noopener noreferrer"},Ce={href:"https://www.pdai.tech/md/arch/arch-z-id.html#mist-%E8%96%84%E9%9B%BE%E7%AE%97%E6%B3%95",target:"_blank",rel:"noopener noreferrer"},Re=e("h3",{id:"你们公司是如何处理分布式事务的",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#你们公司是如何处理分布式事务的"},[e("span",null,"你们公司是如何处理分布式事务的？")])],-1),Me=e("p",null,"如果你真的被问到，可以这么说，我们某某特别严格的场景，用的是 TCC 来保证强一致性；然后其他的一些场景基于 MQ 来实现分布式事务。",-1),Te=e("p",null,"你找一个严格资金要求绝对不能错的场景，你可以说你是用的 TCC 方案；如果是一般的分布式事务场景，订单插入之后要调用库存服务更新库存，库存数据没有资金那么的敏感，可以用可靠消息最终一致性方案。",-1),Ne=e("h2",{id:"高并发",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#高并发"},[e("span",null,[e("em",null,"高并发")])])],-1),Oe={id:"接口幂等性",tabindex:"-1"},je={class:"header-anchor",href:"#接口幂等性"},Pe={href:"https://www.pdai.tech/md/spring/springboot/springboot-x-interface-mideng.html#%E4%BB%80%E4%B9%88%E6%98%AF%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89",target:"_blank",rel:"noopener noreferrer"},qe=n("<ul><li>从幂等和防止重复提交，接口幂等和常见的保证幂等的方式等知识点构筑知识体系 <ul><li>幂等: 更多的是在重复请求已经发生，或是无法避免的情况下，采取一定的技术手段让这些重复请求不给系统带来副作用</li><li>防止重复提交: 更多的是不让用户发起多次一样的请求,主要还是从客户端的角度来解决这个问题</li></ul></li><li>保证幂等方式 <ul><li>数据库层面 <ul><li>悲观锁: for update</li></ul></li><li>唯一 ID/索引</li><li>乐观锁 <ul><li>使用版本号或者时间戳</li><li>状态机</li></ul></li></ul></li><li>分布式锁</li></ul>",1),Ie={id:"秒杀系统",tabindex:"-1"},Fe={class:"header-anchor",href:"#秒杀系统"},De={href:"https://www.pdai.tech/md/arch/arch-example-seckill.html#%E6%9E%B6%E6%9E%84%E6%A1%88%E4%BE%8B---%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1",target:"_blank",rel:"noopener noreferrer"},Qe=n('<p>层层拦截，将请求尽量拦截在系统上游，避免将锁冲落到数据库上。</p><ul><li>第一层：客户端优化</li></ul><p>产品层面，用户点击“查询”或者“购票”后，按钮置灰，禁止用户重复提交请求； JS层面，限制用户在x秒之内只能提交一次请求，比如微信摇一摇抢红包。 基本可以拦截80%的请求。</p><ul><li>第二层：站点层面的请求拦截（nginx层，写流控模块）</li></ul><p>怎么防止程序员写for循环调用，有去重依据么? IP? cookie-id? …想复杂了，这类业务都需要登录，用uid即可。在站点层面，对uid进行请求计数和去重，甚至不需要统一存储计数，直接站点层内存存储（这样计数会不准，但最简单，比如guava本地缓存）。一个uid，5秒只准透过1个请求，这样又能拦住99%的for循环请求。 对于5s内的无效请求，统一返回错误提示或错误页面。</p><p>这个方式拦住了写for循环发HTTP请求的程序员，有些高端程序员（黑客）控制了10w个肉鸡，手里有10w个uid，同时发请求（先不考虑实名制的问题，小米抢手机不需要实名制），这下怎么办，站点层按照uid限流拦不住了。</p><ul><li>第三层：服务层拦截</li></ul><p>方案一：写请求放到队列中，每次只透有限的写请求到数据层，如果成功了再放下一批，直到库存不够，队列里的写请求全部返回“已售完”。</p><p>方案二：或采用漏斗机制，只放一倍的流量进来，多余的返回“已售完”，把写压力转换成读压力。 读请求，用cache，redis单机可以抗10W QPS,用异步线程定时更新缓存里的库存值。</p><p>还有提示“模糊化”，比如火车余票查询，票剩了58张，还是26张，你真的关注么，其实我们只关心有票和无票。</p><ul><li>第四层：数据库层</li></ul><p>浏览器拦截了80%，站点层拦截了99.9%并做了页面缓存，服务层又做了写请求队列与数据缓存，每次透到数据库层的请求都是可控的。 db基本就没什么压力了，通过自身锁机制来控制，避免出现超卖。</p><h2 id="其它" tabindex="-1"><a class="header-anchor" href="#其它"><span><em>其它</em></span></a></h2>',13),Ue={id:"前后端分离接口安全",tabindex:"-1"},ze={class:"header-anchor",href:"#前后端分离接口安全"},Je={href:"https://www.pdai.tech/md/spring/springboot/springboot-x-interface-jiami.html#%E5%B8%B8%E8%A7%81%E7%9A%84%E4%BF%9D%E8%AF%81%E6%8E%A5%E5%8F%A3%E5%AE%89%E5%85%A8%E7%9A%84%E6%96%B9%E5%BC%8F",target:"_blank",rel:"noopener noreferrer"};function Ve(He,Ge){const t=s("ExternalLinkIcon");return d(),r("div",null,[R,e("ul",null,[e("li",null,[e("p",null,[e("a",M,[l("涉及IntegerCache，1000"),T,l("100为true"),a(t)]),l(":")]),N])]),O,e("h5",j,[e("a",P,[e("span",null,[e("a",q,[l("#"),a(t)]),l("工作过程")])])]),I,F,e("h5",D,[e("a",Q,[e("span",null,[e("a",U,[l("#"),a(t)]),l("为什么使用双亲委派模型")])])]),z,e("ul",null,[e("li",null,[e("a",J,[l("Mysql大数据表处理方案"),a(t)])]),e("li",null,[e("a",V,[l("大数据处理流程：数据的抽取、储存、提取"),a(t)])]),e("li",null,[e("a",H,[l("MySQL千万级大表优化"),a(t)])]),e("li",null,[e("a",G,[l("十亿级超大表数据库注入Amazon S3 数据湖的实践"),a(t)])])]),W,Y,e("ul",null,[K,X,e("li",null,[l("缺点 "),e("ul",null,[Z,e("li",null,[l("RedLock算法本身有争议，具体看这篇文章 "),e("a",$,[l("How to do distributed locking"),a(t)]),l(" (opens new window) 以及作者的回复 "),e("a",ee,[l("Is Redlock safe?"),a(t)])])])])]),le,e("ul",null,[te,e("li",null,[l("缺点 "),e("ul",null,[ae,e("li",null,[l("系统复杂度提高 "),e("ul",null,[e("li",null,[l("怎么"),e("a",ne,[l("保证消息没有重复消费"),a(t)]),l("？ "),ie]),e("li",null,[l("怎么"),e("a",se,[l("处理消息丢失的情况"),a(t)]),l("？ "),de])])]),re])])]),oe,e("h3",ce,[e("a",pe,[e("span",null,[e("a",he,[l("分库分表实现"),a(t)])])])]),e("h3",ue,[e("a",ge,[e("span",null,[e("a",_e,[l("分布式锁实现"),a(t)])])])]),e("ul",null,[e("li",null,[e("a",me,[l("基于数据库"),a(t)])]),e("li",null,[e("a",be,[l("基于 Redis"),a(t)]),ve]),e("li",null,[e("a",ke,[l("基于 zookeeper"),a(t)])])]),e("h3",Ee,[e("a",fe,[e("span",null,[e("a",xe,[l("分布式 ID 实现"),a(t)])])])]),e("ul",null,[e("li",null,[l("全局唯一ID "),e("ul",null,[e("li",null,[e("a",ye,[l("UUID"),a(t)])]),e("li",null,[e("a",Ae,[l("数据库生成"),a(t)])]),e("li",null,[e("a",Be,[l("使用redis实现"),a(t)])]),e("li",null,[e("a",Le,[l("雪花算法-Snowflake"),a(t)])]),e("li",null,[e("a",we,[l("百度-UidGenerator"),a(t)])]),e("li",null,[e("a",Se,[l("美团Leaf"),a(t)])]),e("li",null,[e("a",Ce,[l("Mist 薄雾算法"),a(t)])])])])]),Re,Me,Te,Ne,e("h3",Oe,[e("a",je,[e("span",null,[e("a",Pe,[l("接口幂等性"),a(t)])])])]),qe,e("h3",Ie,[e("a",Fe,[e("span",null,[e("a",De,[l("秒杀系统"),a(t)])])])]),Qe,e("h3",Ue,[e("a",ze,[e("span",null,[e("a",Je,[l("前后端分离接口安全"),a(t)])])])])])}const Ke=i(C,[["render",Ve],["__file","interview.html.vue"]]),Xe=JSON.parse('{"path":"/posts/interview/interview.html","title":"个人经验总结","lang":"zh-CN","frontmatter":{"icon":"lock","date":"2022-05-13T00:00:00.000Z","category":["面试"],"tag":["Java","Spring","Redis","MQ","MySql","分布式"],"feed":false,"seo":false,"head":[]},"headers":[{"level":2,"title":"1. Java基础","slug":"_1-java基础","link":"#_1-java基础","children":[{"level":3,"title":"1.1 数据类型","slug":"_1-1-数据类型","link":"#_1-1-数据类型","children":[]},{"level":3,"title":"1.2 强转","slug":"_1-2-强转","link":"#_1-2-强转","children":[]},{"level":3,"title":"1.3 访问修饰符","slug":"_1-3-访问修饰符","link":"#_1-3-访问修饰符","children":[]},{"level":3,"title":"1.4 final 关键字","slug":"_1-4-final-关键字","link":"#_1-4-final-关键字","children":[]},{"level":3,"title":"1.5 Integer小知识:","slug":"_1-5-integer小知识","link":"#_1-5-integer小知识","children":[]},{"level":3,"title":"1.6 NIO 和 IO 区别","slug":"_1-6-nio-和-io-区别","link":"#_1-6-nio-和-io-区别","children":[]},{"level":3,"title":"1.7 hashCode 与 equals?","slug":"_1-7-hashcode-与-equals","link":"#_1-7-hashcode-与-equals","children":[]}]},{"level":2,"title":"2. Java 集合","slug":"_2-java-集合","link":"#_2-java-集合","children":[{"level":3,"title":"2.1 常见集合","slug":"_2-1-常见集合","link":"#_2-1-常见集合","children":[]},{"level":3,"title":"2.2 集合线程安全","slug":"_2-2-集合线程安全","link":"#_2-2-集合线程安全","children":[]}]},{"level":2,"title":"3. Java 并发","slug":"_3-java-并发","link":"#_3-java-并发","children":[{"level":3,"title":"3.1 线程创建几种方式","slug":"_3-1-线程创建几种方式","link":"#_3-1-线程创建几种方式","children":[]},{"level":3,"title":"3.2 线程状态的切换","slug":"_3-2-线程状态的切换","link":"#_3-2-线程状态的切换","children":[]},{"level":3,"title":"3.3 控制线程执行顺序","slug":"_3-3-控制线程执行顺序","link":"#_3-3-控制线程执行顺序","children":[]},{"level":3,"title":"3.4 线程池","slug":"_3-4-线程池","link":"#_3-4-线程池","children":[]},{"level":3,"title":"3.5 ThreadLocal 是什么？","slug":"_3-5-threadlocal-是什么","link":"#_3-5-threadlocal-是什么","children":[]},{"level":3,"title":"3.6 锁","slug":"_3-6-锁","link":"#_3-6-锁","children":[]}]},{"level":2,"title":"4. JVM","slug":"_4-jvm","link":"#_4-jvm","children":[{"level":3,"title":"4.1 JMM","slug":"_4-1-jmm","link":"#_4-1-jmm","children":[]},{"level":3,"title":"4.2 JVM 调优","slug":"_4-2-jvm-调优","link":"#_4-2-jvm-调优","children":[]},{"level":3,"title":"4.3 垃圾回收","slug":"_4-3-垃圾回收","link":"#_4-3-垃圾回收","children":[]},{"level":3,"title":"4.4 类加载","slug":"_4-4-类加载","link":"#_4-4-类加载","children":[]}]},{"level":2,"title":"","slug":"","link":"#","children":[]},{"level":2,"title":"5. 设计模式","slug":"_5-设计模式","link":"#_5-设计模式","children":[]},{"level":2,"title":"6. Spring","slug":"_6-spring","link":"#_6-spring","children":[{"level":3,"title":"6.1 Spring Bean 生命周期","slug":"_6-1-spring-bean-生命周期","link":"#_6-1-spring-bean-生命周期","children":[]},{"level":3,"title":"6.2 Spring Boot 启动顺序","slug":"_6-2-spring-boot-启动顺序","link":"#_6-2-spring-boot-启动顺序","children":[]},{"level":3,"title":"6.3 事务传播机制","slug":"_6-3-事务传播机制","link":"#_6-3-事务传播机制","children":[]},{"level":3,"title":"6.4 事务可能失效原因","slug":"_6-4-事务可能失效原因","link":"#_6-4-事务可能失效原因","children":[]},{"level":3,"title":"6.5 解决循环依赖","slug":"_6-5-解决循环依赖","link":"#_6-5-解决循环依赖","children":[]},{"level":3,"title":"6.6 Spring Cloud/Spring Cloud Alibaba 常用组件","slug":"_6-6-spring-cloud-spring-cloud-alibaba-常用组件","link":"#_6-6-spring-cloud-spring-cloud-alibaba-常用组件","children":[]}]},{"level":2,"title":"7. Mysql","slug":"_7-mysql","link":"#_7-mysql","children":[{"level":3,"title":"7.1 存储引擎","slug":"_7-1-存储引擎","link":"#_7-1-存储引擎","children":[]},{"level":3,"title":"7.2 隔离级别","slug":"_7-2-隔离级别","link":"#_7-2-隔离级别","children":[]},{"level":3,"title":"7.3 执行一条 SQL 查询语句，期间发生了什么？","slug":"_7-3-执行一条-sql-查询语句-期间发生了什么","link":"#_7-3-执行一条-sql-查询语句-期间发生了什么","children":[]},{"level":3,"title":"7.4 MySQL 一行记录是怎么存储的？","slug":"_7-4-mysql-一行记录是怎么存储的","link":"#_7-4-mysql-一行记录是怎么存储的","children":[]},{"level":3,"title":"7.5 SQL 优化","slug":"_7-5-sql-优化","link":"#_7-5-sql-优化","children":[]}]},{"level":2,"title":"8. Redis","slug":"_8-redis","link":"#_8-redis","children":[{"level":3,"title":"8.1 分布式锁","slug":"_8-1-分布式锁","link":"#_8-1-分布式锁","children":[]},{"level":3,"title":"8.2 缓存","slug":"_8-2-缓存","link":"#_8-2-缓存","children":[]},{"level":3,"title":"8.3 持久化","slug":"_8-3-持久化","link":"#_8-3-持久化","children":[]},{"level":3,"title":"8.4 高可用","slug":"_8-4-高可用","link":"#_8-4-高可用","children":[]},{"level":3,"title":"8.5 过期策略","slug":"_8-5-过期策略","link":"#_8-5-过期策略","children":[]}]},{"level":2,"title":"9. MQ","slug":"_9-mq","link":"#_9-mq","children":[{"level":3,"title":"9.1 为什么使用消息队列","slug":"_9-1-为什么使用消息队列","link":"#_9-1-为什么使用消息队列","children":[]},{"level":3,"title":"9.2 如何设计一个消息队列","slug":"_9-2-如何设计一个消息队列","link":"#_9-2-如何设计一个消息队列","children":[]},{"level":3,"title":"9.3 处理大量积压消息","slug":"_9-3-处理大量积压消息","link":"#_9-3-处理大量积压消息","children":[]},{"level":3,"title":"9.4 消息丢失原因及 RabbitMQ 应对方案","slug":"_9-4-消息丢失原因及-rabbitmq-应对方案","link":"#_9-4-消息丢失原因及-rabbitmq-应对方案","children":[]},{"level":3,"title":"9.5 队列模式","slug":"_9-5-队列模式","link":"#_9-5-队列模式","children":[]}]},{"level":2,"title":"10. 分布式","slug":"_10-分布式","link":"#_10-分布式","children":[{"level":3,"title":"跨服务之间分页查询实现及大量数据导出情况","slug":"跨服务之间分页查询实现及大量数据导出情况","link":"#跨服务之间分页查询实现及大量数据导出情况","children":[]},{"level":3,"title":"分库分表实现","slug":"分库分表实现","link":"#分库分表实现","children":[]},{"level":3,"title":"分布式锁实现","slug":"分布式锁实现","link":"#分布式锁实现","children":[]},{"level":3,"title":"分布式 ID 实现","slug":"分布式-id-实现","link":"#分布式-id-实现","children":[]},{"level":3,"title":"你们公司是如何处理分布式事务的？","slug":"你们公司是如何处理分布式事务的","link":"#你们公司是如何处理分布式事务的","children":[]}]},{"level":2,"title":"高并发","slug":"高并发","link":"#高并发","children":[{"level":3,"title":"接口幂等性","slug":"接口幂等性","link":"#接口幂等性","children":[]},{"level":3,"title":"秒杀系统","slug":"秒杀系统","link":"#秒杀系统","children":[]}]},{"level":2,"title":"其它","slug":"其它","link":"#其它","children":[{"level":3,"title":"前后端分离接口安全","slug":"前后端分离接口安全","link":"#前后端分离接口安全","children":[]}]}],"git":{"createdTime":1653376909000,"updatedTime":1713708503000,"contributors":[{"name":"zJiaC","email":"jc456123","commits":5},{"name":"zJiaC","email":"425226133@qq.com","commits":4}]},"readingTime":{"minutes":37.96,"words":11387},"filePathRelative":"posts/interview/interview.md","localizedDate":"2022年5月13日"}');export{Ke as comp,Xe as data};
